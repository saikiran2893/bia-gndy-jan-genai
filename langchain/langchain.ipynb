{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Python is a high-level, interpreted, and general-purpose dynamic programming language that focuses on code readability. Its design philosophy emphasizes coding efficiency, primarily using indentation.\\n\\nPython's syntax allows programmers to express their concepts in fewer lines of code than might be possible in languages such as C++ or Java. It provides constructs that enable clear programming on both small and large scales.\\n\\nPython is widely used for various kinds of software development like web development, data analysis, artificial intelligence, machine learning and more. It also supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming.\\n\\nThe language was created in the late 1980s, and first released in 1991, by Guido van Rossum. Python has seen a large growth in usage over the past few years, due to its user-friendly syntax and wide range of libraries and frameworks.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "user_input = input(\"What do you want to ask the coding assistant?\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_input}\"}\n",
    "    ]\n",
    "\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e256d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install langgraph langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca11d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, interpreted programming language created by Guido van Rossum and first released in 1991. It's designed to be easy to read (with a clear, uncluttered syntax) and powerful, with the ability to scale up for large applications. Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming. \n",
      "\n",
      "Python libraries like NumPy, Pandas, and Matplotlib make it particularly well-suited for various types of scientific computing, data analysis, and visualization. These features, along with its powerful web framework Django, have also made Python a popular language in web development. The versatility and user-friendly nature of Python means it's used in a variety of applications, from simple scripts to complex machine learning algorithms.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_groq import ChatGroq\n",
    "from langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "user_input = input(\"What do you want to ask the coding assistant?\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "    # lm = ChatGroq(\n",
    "    #     model=\"qwen/qwen3-32b\",\n",
    "    #     temperature=0,\n",
    "    #     max_tokens=None,\n",
    "    #     reasoning_format=\"parsed\",\n",
    "    #     timeout=None,\n",
    "    #     max_retries=2,\n",
    "    #     # other params...\n",
    "    # )\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"user_input\": user_input})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Core Abstractions of Langchain:\n",
    "\n",
    "\n",
    "# 1. LLMs. -- ## https://docs.langchain.com/oss/python/integrations/chat\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "response = llm.invoke(\"What is 2+2?\")\n",
    "print(response.content)\n",
    "\n",
    "## Hugging Face Hub Integration\n",
    "from langchain_huggingface import HuggingFaceHub\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-R1-0528\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    "    provider=\"auto\",  # let Hugging Face choose the best provider for you\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Prompts --> # https://reference.langchain.com/python/langchain-core/prompts\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# String template\n",
    "string_template = PromptTemplate.from_template(\n",
    "    \"Tell me about {topic} in {style}\"\n",
    ")\n",
    "print(string_template.format(topic=\"Python\", style=\"simple\"))\n",
    "\n",
    "# Chat template\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a {role}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "messages = chat_template.format_messages(\n",
    "    role=\"teacher\",\n",
    "    question=\"Explain variables\"\n",
    ")\n",
    "print(messages)\n",
    "\n",
    "\n",
    "# 3. Chains\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=string_template)\n",
    "result = chain.run(topic=\"Python\", style=\"simple\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "# 4. Memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {\"input\": \"My name is Alice\"},\n",
    "    {\"output\": \"Nice to meet you, Alice!\"}\n",
    ")\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debececc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting Started with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb93cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07be4955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(key loaded from environment)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ.get(\"OPENAI_API_KEY\") and \"(key loaded from environment)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568482a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8736016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 8192, 'max_output_tokens': 8192, 'text_inputs': True, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'text_outputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': False, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x15455ec90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x154a18c20> root_client=<openai.OpenAI object at 0x154884950> root_async_client=<openai.AsyncOpenAI object at 0x15488b650> model_name='gpt-4' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4\",temperature=1.0)\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9359b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence that has been programmed with the capability to make autonomous decisions and perform actions based on those decisions. These AI systems are conditioned to take full control of the task they are assigned, operating independently without human intervention. They often use machine learning algorithms to improve their performance over time. Agentic AI can be found in various applications such as autonomous vehicles, healthcare diagnostics, trading systems, etc.\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff1fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e4dd704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking about Apple\\'s stock performance. First, I need to check the current stock price. Since I can\\'t access real-time data, I should mention that. Maybe I can provide some context about Apple\\'s recent performance based on available information up to July 2024. Let me recall the key points.\\n\\nApple is a tech giant with a large market cap. Their stock has been performing well due to strong product launches, services growth, and global demand. However, lately, there might have been some fluctuations. For example, the stock price might have been affected by factors like interest rates, supply chain issues, or market saturation. Also, the launch of new products like the iPhone 15 could influence investor sentiment. I should note any recent earnings reports‚Äîmaybe they had a good quarter with higher-than-expected revenue. Additionally, the stock\\'s performance in the broader market context, like how the Nasdaq or S&P 500 is doing. It\\'s important to mention the 10-year beta to show volatility. Also, consider any upcoming events, like product launches or regulatory issues. The user might be interested in whether now is a good time to invest, but I should avoid giving financial advice. Instead, suggest consulting a financial advisor. Keep the response balanced, highlighting both positive and potential negative factors affecting the stock. Make sure to emphasize the need for real-time data and professional advice.\\n</think>\\n\\nAs of my knowledge cutoff in July 2024, I cannot provide **real-time stock prices** for Apple (AAPL). However, I can offer context based on historical trends and factors that typically influence Apple\\'s stock performance:\\n\\n---\\n\\n### **Key Factors Affecting Apple Stock (as of 2024):**\\n1. **Strong Earnings and Services Growth**  \\n   - Apple consistently reports robust revenue from iPhones, Macs, and its growing services segment (Apple Music, iCloud, App Store, etc.).  \\n   - Recent quarterly earnings (if available) may have exceeded analyst expectations, driven by strong demand for new products like the iPhone 15 or M3 MacBooks.\\n\\n2. **Market Conditions**  \\n   - The broader tech sector (e.g., NASDAQ) and global economic trends (interest rates, inflation) impact investor sentiment. If markets are bullish on tech, Apple often benefits.  \\n   - A **10-year beta** of ~0.85 historically indicates Apple is slightly less volatile than the market.\\n\\n3. **Product Launches and Innovation**  \\n   - Upcoming or recent product cycles (e.g., iPhone 15, Apple Watch Ultra 2, or AI integration) can drive investor confidence.  \\n   - Rumors about Apple\\'s AI roadmap or potential new product categories (e.g., AR/VR headset) could boost the stock.\\n\\n4. **Geopolitical and Regulatory Risks**  \\n   - Supply chain issues (e.g., manufacturing in China) or regulatory challenges (e.g., antitrust cases in the EU/US) might create short-term volatility.\\n\\n5. **Valuation Metrics**  \\n   - Apple‚Äôs **P/E ratio** (price-to-earnings) and **P/S ratio** (price-to-sales) are often compared to peers like Microsoft or Amazon to assess whether it‚Äôs overvalued or undervalued.\\n\\n---\\n\\n### **How to Check Real-Time Performance**\\nTo get the latest stock price, use:\\n- **Financial platforms**: Yahoo Finance, Bloomberg, or Google Finance.\\n- **Trading apps**: Robinhood, TD Ameritrade, or E*TRADE (free real-time data for non-clients).\\n- **Search engines**: Type \"AAPL stock price\" or \"Apple stock today\" for instant updates.\\n\\n---\\n\\n### **Long-Term Outlook**\\nApple is a **blue-chip stock** with a dominant market share in consumer electronics and a loyal customer base. While short-term fluctuations are inevitable, its long-term growth has historically been resilient due to brand strength and recurring revenue from services.\\n\\n---\\n\\n### **Caveat**\\nStock performance depends on real-time market conditions, earnings surprises, and macroeconomic factors. For personalized advice, consult a financial advisor. Let me know if you\\'d like help analyzing trends or historical data! üçéüìà', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 874, 'prompt_tokens': 15, 'total_tokens': 889, 'completion_time': 2.940007199, 'completion_tokens_details': None, 'prompt_time': 0.000410244, 'prompt_tokens_details': None, 'queue_time': 0.159280461, 'total_time': 2.940417443}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c7e8f-4c2c-7b30-9d07-0e7f3e667990-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 874, 'total_tokens': 889})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "model.invoke(\"How is APple stock doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857f353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI Engineer. Please answer the following question in detail. '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Templates\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",\"You are an AI Engineer. Please answer the following question in detail. \"),\n",
    "     (\"user\",\"{input}\")\n",
    "    ])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39516c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI Engineer. Please answer the following question in detail. '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 8192, 'max_output_tokens': 8192, 'text_inputs': True, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'text_outputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': False, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x15455ec90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x154a18c20>, root_client=<openai.OpenAI object at 0x154884950>, root_async_client=<openai.AsyncOpenAI object at 0x15488b650>, model_name='gpt-4', temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5220c8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In artificial intelligence and computer science, an agent is an autonomous entity which observes through sensors and acts upon an environment using actuators (i.e., it is an actor situated into an environment), and directs its activity towards achieving goals. It can be anything that perceives its environment through sensors and acts upon that environment through effectors.\\n\\nAn Agent can be simple or complex, from a small program that sets an alarm at a particular time, to a sophisticated system that controls a Mars rover. Two fundamental Agent types exist: physical and virtual.\\n\\n1. Physical Agents: They exist in the world physically and can perceive their environment via sensors and act on it via actuators. Examples include industrial robots, Roomba vacuum cleaners, or autonomous cars.\\n\\n2. Virtual Agents: They exist in the form of software and their environment is the computer device they are running on. Examples include a chess program, a web browser, or a recommendation system.\\n\\nIn essence, an agent is a self-contained, interactive system capable of making decisions and taking actions to meet specific objectives or perform certain tasks. The AI models of these agents often involve aspects of machine learning, allowing them to adapt and improve their behavior over time based on their experiences.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"What is Agent?\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "782e1db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'capital': 'New Delhi'}\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "JSON_Output_Parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \" Please answer the following question in detail.\\n{format_instructions}\\n{query}\"\n",
    ")\n",
    "# You can get the format instructions from the parser\n",
    "format_instructions = JSON_Output_Parser.get_format_instructions()\n",
    "llm=ChatOpenAI(model=\"gpt-4\",temperature=0.5)\n",
    "\n",
    "chain = prompt | llm | JSON_Output_Parser\n",
    "response=chain.invoke({\"query\":\"what is capital of India\",\"format_instructions\":format_instructions})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "146c9580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct agent, or Reactive agent, constitutes a fundamental concept in artificial intelligence, specifically under the branch of agent-based systems. \n",
      "\n",
      "An agent, in the context of AI, refers to an entity that perceives its environment through sensors and interacts with that environment via actuators based on a specific set of rules or behaviors. In a similar vein, a ReAct (Reactive) agent is a type of AI entity that reacts to changes in its environment without the need for internal pre-planned goals or representations of the environment. \n",
      "\n",
      "The main characteristic of the ReAct agent is that it always has a direct mapping from its perceptual history to action. Unlike goal-based or utility-based agents, a Reactive agent doesn't consider future consequences of actions, their desirability, or success in achieving long-term goals. It reacts to the current situation based on the set of stimulus-response rule pairs it has. This architecture makes them fast, highly responsive, and simple.\n",
      "\n",
      "Each response that a ReAct agent makes is independent of any other reaction, and these responses tend to occur almost instantaneously. These characteristics make ReAct agents particularly well-suited to rapidly changing environments, where quick decision making is crucial. Examples of Reactive agents are found in video games (NPCs), robotics (obstacle avoidance) and certain types of automated trading systems.\n",
      "\n",
      "However, despite their strengths, ReAct agents also have limitations. They lack the ability to plan and make decisions based on internal goals, as they only respond to external stimuli. Hence, they often cannot handle complex scenarios that require advanced reasoning or long-term strategic planning. They can also have problems in situations that require them to have knowledge about unobservable aspects of their environment.\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "Str_Output_Parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | Str_Output_Parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about ReAct agent?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c295905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strucutred output using Langchain\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    rating: Optional[int] = Field(description=\"Rating of the joke from 1 to 10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aea15344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 8192, 'max_output_tokens': 8192, 'text_inputs': True, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'text_outputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': False, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x1554d9520> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1554db500> root_client=<openai.OpenAI object at 0x15455e5d0> root_async_client=<openai.AsyncOpenAI object at 0x1554d95e0> model_name='gpt-4' temperature=0.5 model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4\",temperature=0.5)\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d65bafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup=\"Why don't scientists trust atoms?\" punchline='Because they make up everything!' rating=8\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='''Answer the user query. You must respond with valid JSON that has exactly these keys:\n",
    "- \"setup\": the setup of the joke (string)\n",
    "- \"punchline\": the punchline (string)\n",
    "- \"rating\": optional, 1-10 (integer or null) \\n \n",
    "Example: {{\"setup\":\"why did the chicken cross the road?\" \\n \"punchline\":\"to get to the other side!\" \\n \"rating\": 7}} \\n\n",
    "{query}\\n in the following format \\n {format_instructions}''',\n",
    "    input_variables=[\"query\",\"format_instructions\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "user_input = input(\"Ask for a joke: \")\n",
    "response = chain.invoke({\"query\":\"{user_input}\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
